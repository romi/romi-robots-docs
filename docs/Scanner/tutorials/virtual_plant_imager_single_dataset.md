How to use the Virtual Plant Imager to generate a single virtual plant dataset
===

## Objective
Working with virtual plants instead of real ones makes data acquisition inexpensive and has the advantage to parametrize the type of data.
By design, ground truth data can be easily extracted from virtual datasets for evaluation purposes and building machine learning models.
The Virtual Plant Imager is designed two address these two issues.
After reading this tutorial, you should be able to generate a single virtual plant dataset in order to evaluate the robustness of [plant-3d-vision](https://github.com/romi/plant-3d-vision).

## Prerequisite
If it is not already done, you must be able to build and run the docker image by following the [instructions](../docker/virtualplantimager_docker.md).

## Step-by-step tutorial
Principle: Technically, the `Virtual Plant Imager` relies on [Blender v2.81a](https://www.blender.org/) to generate the images of 3d model of the plants.
The 3d model can be provided as an input or can be also generated by [lpy](https://lpy.readthedocs.io/en/latest/) based on biological rules.
An Http server acts as an interface to drive Blender generation scripts.

### 1. Preparing your scan data
First, you have to create a working database on your host machine, let's say `home/host/path/database_example`. You can find an example of this database [here](https://github.com/romi/plant-imager/tree/master/database_example).

You can obtain sample data for the scanner here, and put it in the data folder.
```bash
wget https://db.romi-project.eu/models/arabidopsis_data.zip
unzip arabidopsis_data.zip -d data
```

To use custom data, it must consist in `.obj` file, in which each type of organ corresponds to a distinct mesh.
This mesh must have a single material whose name is the name of the organ.
The data dir must contain the `obj` and `mtl` files.

Additionally, background HDRI files can be downloaded from [hdri haven](https://hdrihaven.com/).
Download `.hdr` files and put them in the `hdri` folder.

### 2. Generate a virtual plant with lpy
After preparing your working database directory. You have to run the docker container with the database mounted.
```bash
cd plant-imager/docker
./run.sh -db /home/host/path/database_example  # This will map to `db` directory located in the the docker's user home
```

Finally, you can generate the virtual dataset by running the following command
```bash
(lpyEnv) user@5c9e389f223d  romi_run_task --config plant-imager/config/vscan_lpy_blender.toml VirtualScan db/generated_dataset # Run VirtualScan by specifying the output folder generated_dataset
```

The lpy parameters that are used in the config [file](https://github.com/romi/plant-imager/blob/master/config/vscan_lpy_blender.toml) can be customized for your purpose.
```toml
[VirtualPlant.lpy_globals]
BRANCHON = false
MEAN_NB_DAYS = 70
STDEV_NB_DAYS = 5
BETA = 51
INTERNODE_LENGTH = 1.3
STEM_DIAMETER = 0.09
```

## Running the reconstruction pipeline on the virtual dataset

If not installed yet, please refer to [Plant-3d-Vision](../tutorials/reconstruct_scan.md) documentation.

With virtual data, you may want to use ground truth poses:
```toml
[Voxels]
use_colmap_poses = false
[Masks]
upstream_task = Scan
```

Then the pipeline can be run as usual and `colmap` will not be run.

To test the plant reconstruction pipeline on an example `/home/host/my_virtual_plant`:
```bash
romi_run_task --config plant-3d-vision/config/geom_pipe_virtual.toml PointCloud /home/host/my_virtual_plant
```
This should process all dependencies to obtain a segmented "PointCloud.ply" !
